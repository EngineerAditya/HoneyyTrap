"""
Honeypot API - Main FastAPI Application
"""

import os
import json
import requests
from fastapi import FastAPI, Header, HTTPException, Depends
from fastapi.middleware.cors import CORSMiddleware
from dotenv import load_dotenv

import google.generativeai as genai

from .models import HoneypotRequest, HoneypotResponse, ErrorResponse
from .intelligence import IntelligenceExtractor, session_store
from .agent.manager import AgentManager
from .agent.states import AgentState


# --------------------------------------------------
# ENV + CONFIG
# --------------------------------------------------
load_dotenv()

API_KEY = os.getenv("HONEYPOT_API_KEY", "test-api-key-change-me")
GUVI_ENDPOINT = "https://hackathon.guvi.in/api/updateHoneyPotFinalResult"

genai.configure(api_key=os.getenv("GEMINI_API_KEY"))
gemini_model = genai.GenerativeModel("gemini-1.5-flash")


# --------------------------------------------------
# FASTAPI APP
# --------------------------------------------------
app = FastAPI(
    title="Honeypot Scam Detection API",
    description="AI-powered honeypot for detecting scams and extracting intelligence",
    version="1.0.0"
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

extractor = IntelligenceExtractor()
agent = AgentManager()


# --------------------------------------------------
# AUTH
# --------------------------------------------------
def verify_api_key(x_api_key: str = Header(...)):
    if x_api_key != API_KEY:
        raise HTTPException(status_code=401, detail="Invalid API key")
    return x_api_key


# --------------------------------------------------
# HEALTH
# --------------------------------------------------
@app.get("/health")
def health_check():
    return {"status": "healthy", "message": "Honeypot API is running"}


# --------------------------------------------------
# GEMINI REPLY (LLM ONLY TALKS)
# --------------------------------------------------
def generate_llm_reply(message_text: str, llm_context: dict, history: list):
    prompt = f"""
You are a cautious but cooperative user talking to a potential scammer.
You NEVER share OTP, PIN, UPI, passwords, or card details.
Your goal is to delay and extract more information naturally.

Conversation context:
{json.dumps(llm_context, indent=2)}

Incoming message:
"{message_text}"

Respond naturally, ask clarifying questions, and stay safe.
"""

    response = gemini_model.generate_content(
        prompt,
        generation_config={
            "temperature": 0.7,
            "max_output_tokens": 120
        }
    )

    return response.text.strip()


# --------------------------------------------------
# MAIN ENDPOINT
# --------------------------------------------------
@app.post(
    "/honeypot",
    response_model=HoneypotResponse,
    responses={
        401: {"model": ErrorResponse},
        422: {"model": ErrorResponse}
    }
)
def process_message(
    request: HoneypotRequest,
    api_key: str = Depends(verify_api_key)
):
    session_id = request.sessionId

    print(f"\n[SESSION: {session_id}] Message: {request.message.text}")

    # --------------------------------------------------
    # RESET SESSION IF NEW CONVERSATION
    # --------------------------------------------------
    if len(request.conversationHistory) == 0:
        session_store.clear_session(session_id)

    # --------------------------------------------------
    # INTELLIGENCE EXTRACTION
    # --------------------------------------------------
    current_intel = extractor.extract(request.message.text)
    session = session_store.add_intelligence(session_id, current_intel)

    print(f"[SESSION: {session_id}] Scam detected: {session.scam_detected}")
    print(f"[SESSION: {session_id}] Message count: {session.message_count}")

    # --------------------------------------------------
    # TERMINATION LOGIC (CRITICAL)
    # --------------------------------------------------
    should_terminate = False

    # Non-scam: stop early
    if not session.scam_detected and session.message_count >= 5:
        should_terminate = True

    # Scam honeypot: extended conversation
    elif session.scam_detected and session.message_count >= 15:
        should_terminate = True

    # --------------------------------------------------
    # TERMINATE â†’ GUVI CALLBACK
    # --------------------------------------------------
    if should_terminate:
        payload = session_store.get_final_payload(
            session_id,
            agent_notes="Auto-generated by Agentic Honeypot"
        )

        print("\n[CALLBACK PAYLOAD]")
        print(json.dumps(payload, indent=2))

        try:
            requests.post(GUVI_ENDPOINT, json=payload, timeout=5)
        except Exception as e:
            print(f"[CALLBACK ERROR] {e}")

        return HoneypotResponse(
            status="success",
            reply="Thank you. I will check this and get back later."
        )

    # --------------------------------------------------
    # LLM CONTEXT + REPLY
    # --------------------------------------------------
    llm_context = session.to_llm_context()

    ai_reply = generate_llm_reply(
        request.message.text,
        llm_context,
        request.conversationHistory
    )

    return HoneypotResponse(
        status="success",
        reply=ai_reply
    )


# --------------------------------------------------
# RUN
# --------------------------------------------------
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)